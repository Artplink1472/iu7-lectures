\lesson{1}{Теоретическая информатика}

\section{Информатика как наука}

\begin{definition}
  Информатика - наука, изучающая аспекты:
  \begin{itemize}
    \item получаения информации;
    \item хранения информации;
    \item использования информации;
    \item передачи информации.
  \end{itemize}
\end{definition}

\begin{definition}
  Информатика - это наука о формализации любых задач, разработки алгоритмов для их решения и решение этих задач с использованием компьютеров и компьютерных сетей.
\end{definition}

\subsection{Задачи информатики}

\begin{itemize}
  \item Исследование информационных процессов любой природы;
  \item Создание новых технологий переработки информации;
  \item Решение научных и инженерных проблем создания, внедрения и обеспечения эффективного использования компьютерной техники во всех сферах жизни.
\end{itemize}

\begin{definition}
  Информация - множество фактов о различных объектах, событиях и процессах природы и общества, которое воспринимается в виде образов различной физической природы.
\end{definition}

\begin{definition}
  Информация - это мера уменьшения неопределённости нашего знания о состоянии какого-либо объекта.
\end{definition}


\subsubsection{Схема обработки информации:}

Внешние сигналы 
→ Данные 
→ Неформальный смысл, выраженный в ощущениях 
→ Полуформальный смысл, выраженный в словах 
→ Формальный смысл, выраженный в терминах логики

\subsubsection{Свойства информации}
\begin{enumerate}  
  \item Достоверность - отражает истинное состояние объекта;
  \item Ясность - информация должна быть понятной тому, для кого она предназначена;
  \item Полезность (ценность) - возможность использовать полученную информацию для достижения заданной цели;
  \item Полнота (достаточность) - информация содержит минимальный, но достаточный для принятия правильного решения набор сведений;
  \item Устойчивость - информация должна реагировать на изменение входных данных.
  \item \textbf{Устойчивость} - способность реагировать на изменения исходных данных без нарушения необходимой точности.
  \item Способность информации к накоплению и размножению.
  \item Информация порождает новую информацию.
  \item Информация - товар, т.е. подлежит купле-продаже.
\end{enumerate} 

\subsubsection{Количественная мера информации}

Система $X$ может принимать $N$ состояний $x_1, x_2, \ldots, x_{n}$ с вероятностями $p_1, p_2, \ldots, p_n$. \\
\textbf{Энтропия} - мера неопределённости системы - вычисляется по следующей формуле: \[
H(X) = - \sum_{i=1}^{n} p_i \log_a p_i
\]  

Если система имеет 2 равновероятных состояния, то энтропия измеряется в "двоичных единицах" - битах.

